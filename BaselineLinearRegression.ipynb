{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsRhZGtCZlEgBhH1WVpwLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucyMariel/Lucy/blob/master/BaselineLinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use scratch_train_test_split to split the dataset and solve the regression problem."
      ],
      "metadata": {
        "id": "sg8-vLrNBSun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression\n",
        "If the variable of interest is continuous value, it is treated as a regression problem.\n",
        "\n",
        "example:\n",
        "\n",
        "Given a set of attributes, determine the selling price of a given house"
      ],
      "metadata": {
        "id": "KW7GKZ8UBicG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3: Creating code to solve a regression problem**\n",
        "Question 3 uses train.csv data from the House Prices competition.\n",
        "To implement the following, obtain the above csv data and place it in the same directory.\n",
        "\n",
        "data preparation"
      ],
      "metadata": {
        "id": "nqOWY_ClBrRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('train.csv')\n",
        "X = train[['GrLivArea','YearBuilt']].values\n",
        "y = train[['SalePrice']].values\n",
        "X_train, X_test, y_train, y_test = scratch_train_test_split(X,y,train_size=0.8,random_state=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "qk6p_PtlCAWB",
        "outputId": "3538c35a-daa6-4b04-8371-247c1ddf92d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scratch_train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ec8bd6e2acd4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GrLivArea'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'YearBuilt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscratch_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scratch_train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the scratch_train_test_split function\n",
        "def scratch_train_test_split(X, y, test_size=0.2, train_size=None, random_state=None):\n",
        "    \"\"\"\n",
        "    Splits the data into training and testing sets.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy array or pandas DataFrame): Features.\n",
        "    y (numpy array or pandas Series): Target variable.\n",
        "    test_size (float): Proportion of the dataset to include in the test split (between 0.0 and 1.0).\n",
        "    train_size (float): Proportion of the dataset to include in the train split (between 0.0 and 1.0).\n",
        "    random_state (int): Seed used by the random number generator (for reproducibility).\n",
        "\n",
        "    Returns:\n",
        "    X_train, X_test, y_train, y_test: Split datasets.\n",
        "    \"\"\"\n",
        "    if random_state:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    # Shuffle indices\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Calculate split index\n",
        "    if train_size:\n",
        "        split_idx = int(X.shape[0] * train_size)\n",
        "    else:\n",
        "        split_idx = int(X.shape[0] * (1 - test_size))\n",
        "\n",
        "    # Split the data\n",
        "    train_indices = indices[:split_idx]\n",
        "    test_indices = indices[split_idx:]\n",
        "\n",
        "    X_train = X[train_indices]\n",
        "    X_test = X[test_indices]\n",
        "    y_train = y[train_indices]\n",
        "    y_test = y[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Load your dataset\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "X = train[['GrLivArea', 'YearBuilt']].values\n",
        "y = train[['SalePrice']].values\n",
        "\n",
        "# Split the data using the custom train_test_split function\n",
        "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8, random_state=0)\n",
        "\n",
        "# Output the results\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"X_test:\", X_test)\n",
        "print(\"y_train:\", y_train)\n",
        "print(\"y_test:\", y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1ntjblgCiSP",
        "outputId": "f5957114-ba1f-4269-eb3b-d61448f115a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: [[ 800 1936]\n",
            " [1304 1976]\n",
            " [ 925 1965]\n",
            " ...\n",
            " [1616 1995]\n",
            " [1250 2006]\n",
            " [ 882 1959]]\n",
            "X_test: [[1601 1958]\n",
            " [1196 1916]\n",
            " [1652 2006]\n",
            " [1680 1976]\n",
            " [1314 2007]\n",
            " [ 691 1920]\n",
            " [ 858 1971]\n",
            " [1601 2001]\n",
            " [1829 2003]\n",
            " [1040 1950]\n",
            " [1176 1937]\n",
            " [1915 1992]\n",
            " [1908 1994]\n",
            " [1343 1921]\n",
            " [1513 1920]\n",
            " [1992 2003]\n",
            " [1269 1960]\n",
            " [1786 2001]\n",
            " [2524 1981]\n",
            " [1350 1974]\n",
            " [ 912 1947]\n",
            " [ 784 1928]\n",
            " [1828 2007]\n",
            " [1077 1922]\n",
            " [1494 1997]\n",
            " [1155 1961]\n",
            " [ 999 1962]\n",
            " [ 630 1972]\n",
            " [1200 1965]\n",
            " [1494 1995]\n",
            " [1470 1954]\n",
            " [1868 1984]\n",
            " [2098 2005]\n",
            " [1400 1978]\n",
            " [ 969 1975]\n",
            " [2113 1995]\n",
            " [2080 1969]\n",
            " [2295 1992]\n",
            " [1494 2002]\n",
            " [2898 1976]\n",
            " [2822 2008]\n",
            " [1422 1981]\n",
            " [1664 1965]\n",
            " [1928 2003]\n",
            " [1656 2003]\n",
            " [1285 1948]\n",
            " [ 904 1922]\n",
            " [1440 1900]\n",
            " [2398 1996]\n",
            " [1113 1950]\n",
            " [1082 1948]\n",
            " [1855 1954]\n",
            " [1779 1955]\n",
            " [1349 2000]\n",
            " [1651 1986]\n",
            " [1054 1969]\n",
            " [1040 1949]\n",
            " [1432 1910]\n",
            " [ 720 1949]\n",
            " [1112 1976]\n",
            " [1709 2004]\n",
            " [ 838 1918]\n",
            " [2093 1986]\n",
            " [1296 1967]\n",
            " [1385 1952]\n",
            " [1012 1920]\n",
            " [3140 2008]\n",
            " [ 886 1938]\n",
            " [ 864 1959]\n",
            " [1586 1979]\n",
            " [1512 2000]\n",
            " [1968 1969]\n",
            " [3228 1992]\n",
            " [1006 1959]\n",
            " [1232 1984]\n",
            " [1664 1947]\n",
            " [1750 1940]\n",
            " [1720 2004]\n",
            " [1964 1911]\n",
            " [ 965 1965]\n",
            " [1316 2007]\n",
            " [2514 1990]\n",
            " [1392 1977]\n",
            " [1982 1989]\n",
            " [1348 1925]\n",
            " [1484 1971]\n",
            " [1320 2003]\n",
            " [ 872 1971]\n",
            " [1696 1962]\n",
            " [ 986 1926]\n",
            " [1484 2006]\n",
            " [1852 2009]\n",
            " [1493 1997]\n",
            " [1936 2000]\n",
            " [1078 1950]\n",
            " [1352 1958]\n",
            " [2345 1932]\n",
            " [2031 2002]\n",
            " [1694 2008]\n",
            " [1922 2005]\n",
            " [2084 2004]\n",
            " [1266 2007]\n",
            " [1034 1940]\n",
            " [1090 2005]\n",
            " [1034 1976]\n",
            " [1652 2000]\n",
            " [1987 1994]\n",
            " [1226 2009]\n",
            " [1362 1961]\n",
            " [ 894 1972]\n",
            " [1929 2001]\n",
            " [1092 1930]\n",
            " [1352 1969]\n",
            " [1796 1963]\n",
            " [1111 1926]\n",
            " [1686 1980]\n",
            " [ 987 1972]\n",
            " [1913 1928]\n",
            " [2531 1995]\n",
            " [ 720 1920]\n",
            " [ 789 1926]\n",
            " [1092 1964]\n",
            " [1456 1948]\n",
            " [1464 1963]\n",
            " [1297 1954]\n",
            " [1839 1998]\n",
            " [1839 1957]\n",
            " [1180 1922]\n",
            " [2320 1945]\n",
            " [2112 1969]\n",
            " [2192 1939]\n",
            " [1229 1980]\n",
            " [ 848 2003]\n",
            " [1472 1991]\n",
            " [1456 2007]\n",
            " [ 996 1992]\n",
            " [4676 2007]\n",
            " [1352 2006]\n",
            " [1477 1928]\n",
            " [1552 2005]\n",
            " [1702 2008]\n",
            " [2630 1998]\n",
            " [2022 1977]\n",
            " [1960 1952]\n",
            " [1126 1977]\n",
            " [1788 1957]\n",
            " [1475 1977]\n",
            " [1217 1980]\n",
            " [1548 1976]\n",
            " [ 816 1982]\n",
            " [1756 1996]\n",
            " [ 864 1955]\n",
            " [1811 1956]\n",
            " [ 790 1930]\n",
            " [1218 1972]\n",
            " [1959 2006]\n",
            " [1552 1975]\n",
            " [1003 1984]\n",
            " [1040 1959]\n",
            " [1277 1970]\n",
            " [1053 1959]\n",
            " [2046 2003]\n",
            " [1316 1929]\n",
            " [ 990 1994]\n",
            " [1217 1990]\n",
            " [1851 1964]\n",
            " [1768 1914]\n",
            " [ 928 1956]\n",
            " [1102 2004]\n",
            " [1054 1963]\n",
            " [1074 1975]\n",
            " [1718 1998]\n",
            " [1742 1882]\n",
            " [1638 1998]\n",
            " [1768 2007]\n",
            " [ 948 1968]\n",
            " [1464 2007]\n",
            " [2031 1998]\n",
            " [1980 2004]\n",
            " [1632 1966]\n",
            " [2158 1950]\n",
            " [1422 2004]\n",
            " [1040 1950]\n",
            " [ 754 1935]\n",
            " [1367 1900]\n",
            " [1212 1977]\n",
            " [1675 1999]\n",
            " [1721 1994]\n",
            " [1422 1960]\n",
            " [1110 1978]\n",
            " [1211 1968]\n",
            " [1334 1977]\n",
            " [1406 1920]\n",
            " [1939 2006]\n",
            " [ 936 1956]\n",
            " [2008 1948]\n",
            " [1739 1999]\n",
            " [1204 1998]\n",
            " [1200 2005]\n",
            " [1140 2006]\n",
            " [1230 1910]\n",
            " [1738 1920]\n",
            " [ 768 1972]\n",
            " [2028 2005]\n",
            " [1363 1954]\n",
            " [ 935 1965]\n",
            " [2161 2007]\n",
            " [2872 1977]\n",
            " [1294 1991]\n",
            " [1440 1977]\n",
            " [1563 2007]\n",
            " [1144 1959]\n",
            " [1690 2000]\n",
            " [1688 1997]\n",
            " [1692 2009]\n",
            " [2110 1968]\n",
            " [1240 2006]\n",
            " [1665 2001]\n",
            " [1200 2005]\n",
            " [1266 2005]\n",
            " [2138 1898]\n",
            " [ 520 1927]\n",
            " [1287 1959]\n",
            " [1077 1939]\n",
            " [2624 1918]\n",
            " [1520 1932]\n",
            " [2614 1974]\n",
            " [1541 2005]\n",
            " [1416 1918]\n",
            " [2097 2005]\n",
            " [1291 1996]\n",
            " [ 958 1960]\n",
            " [2392 2003]\n",
            " [1479 1972]\n",
            " [ 864 1971]\n",
            " [ 334 1946]\n",
            " [1056 1954]\n",
            " [ 832 1954]\n",
            " [1336 1953]\n",
            " [1656 1960]\n",
            " [ 958 1976]\n",
            " [ 936 1980]\n",
            " [1121 1963]\n",
            " [1405 2003]\n",
            " [1314 2006]\n",
            " [1339 1958]\n",
            " [3086 1946]\n",
            " [ 816 1963]\n",
            " [3627 1995]\n",
            " [1632 1967]\n",
            " [1962 2006]\n",
            " [ 747 1926]\n",
            " [1812 1900]\n",
            " [ 768 1972]\n",
            " [ 990 1994]\n",
            " [1845 1992]\n",
            " [1446 1996]\n",
            " [1328 1963]\n",
            " [1360 1984]\n",
            " [1509 2003]\n",
            " [1264 1960]\n",
            " [1824 1971]\n",
            " [2622 1994]\n",
            " [2468 2004]\n",
            " [ 901 1954]\n",
            " [ 924 1975]\n",
            " [1593 2001]\n",
            " [ 904 1966]\n",
            " [1166 2005]\n",
            " [1507 1960]\n",
            " [2183 1988]\n",
            " [1453 1986]\n",
            " [ 900 1951]\n",
            " [1574 1976]\n",
            " [1416 1915]\n",
            " [1167 1992]\n",
            " [1717 2006]\n",
            " [1976 2006]\n",
            " [1970 2006]\n",
            " [1620 2007]\n",
            " [1501 1999]\n",
            " [ 672 1940]\n",
            " [ 990 1994]\n",
            " [ 958 1976]\n",
            " [1539 1904]\n",
            " [1644 1989]\n",
            " [2090 1984]\n",
            " [2243 1990]\n",
            " [1308 1940]\n",
            " [1306 1940]\n",
            " [1328 1925]\n",
            " [ 858 1971]]\n",
            "y_train: [[ 60000]\n",
            " [115000]\n",
            " [117500]\n",
            " ...\n",
            " [236500]\n",
            " [171900]\n",
            " [106500]]\n",
            "y_test: [[140000]\n",
            " [109900]\n",
            " [325000]\n",
            " [136905]\n",
            " [230000]\n",
            " [ 86000]\n",
            " [ 88000]\n",
            " [272000]\n",
            " [237000]\n",
            " [109500]\n",
            " [134900]\n",
            " [220000]\n",
            " [210000]\n",
            " [154900]\n",
            " [137500]\n",
            " [250000]\n",
            " [155000]\n",
            " [223500]\n",
            " [278000]\n",
            " [165000]\n",
            " [ 80500]\n",
            " [ 76000]\n",
            " [314813]\n",
            " [ 91000]\n",
            " [217000]\n",
            " [148000]\n",
            " [132500]\n",
            " [ 75500]\n",
            " [146000]\n",
            " [270000]\n",
            " [135000]\n",
            " [178000]\n",
            " [275500]\n",
            " [149500]\n",
            " [122000]\n",
            " [350000]\n",
            " [135000]\n",
            " [268000]\n",
            " [221000]\n",
            " [287000]\n",
            " [582933]\n",
            " [175500]\n",
            " [100000]\n",
            " [219500]\n",
            " [165400]\n",
            " [127000]\n",
            " [ 61000]\n",
            " [ 79000]\n",
            " [315750]\n",
            " [147000]\n",
            " [119200]\n",
            " [136900]\n",
            " [170000]\n",
            " [179000]\n",
            " [184000]\n",
            " [151000]\n",
            " [ 90000]\n",
            " [132000]\n",
            " [ 72500]\n",
            " [ 85000]\n",
            " [137500]\n",
            " [130000]\n",
            " [215000]\n",
            " [ 90000]\n",
            " [166000]\n",
            " [118400]\n",
            " [485000]\n",
            " [ 91300]\n",
            " [127500]\n",
            " [181000]\n",
            " [168500]\n",
            " [172000]\n",
            " [430000]\n",
            " [ 80000]\n",
            " [162500]\n",
            " [159000]\n",
            " [160000]\n",
            " [183500]\n",
            " [130000]\n",
            " [119900]\n",
            " [200141]\n",
            " [250000]\n",
            " [161750]\n",
            " [228500]\n",
            " [117000]\n",
            " [175000]\n",
            " [162000]\n",
            " [123000]\n",
            " [143900]\n",
            " [102000]\n",
            " [265900]\n",
            " [252678]\n",
            " [208900]\n",
            " [230500]\n",
            " [142125]\n",
            " [130000]\n",
            " [239000]\n",
            " [237000]\n",
            " [245350]\n",
            " [377426]\n",
            " [233000]\n",
            " [159895]\n",
            " [109000]\n",
            " [157000]\n",
            " [169900]\n",
            " [251000]\n",
            " [301500]\n",
            " [198900]\n",
            " [163000]\n",
            " [149900]\n",
            " [226000]\n",
            " [ 55000]\n",
            " [158000]\n",
            " [140000]\n",
            " [116900]\n",
            " [207500]\n",
            " [ 94500]\n",
            " [177000]\n",
            " [290000]\n",
            " [ 34900]\n",
            " [ 96500]\n",
            " [145000]\n",
            " [ 91500]\n",
            " [175000]\n",
            " [153000]\n",
            " [221000]\n",
            " [257500]\n",
            " [137500]\n",
            " [259500]\n",
            " [206900]\n",
            " [179500]\n",
            " [124000]\n",
            " [136500]\n",
            " [160000]\n",
            " [179540]\n",
            " [147000]\n",
            " [184750]\n",
            " [208900]\n",
            " [145000]\n",
            " [212900]\n",
            " [367294]\n",
            " [315000]\n",
            " [192000]\n",
            " [124500]\n",
            " [175000]\n",
            " [161500]\n",
            " [127000]\n",
            " [120000]\n",
            " [155000]\n",
            " [138000]\n",
            " [204000]\n",
            " [115000]\n",
            " [230000]\n",
            " [ 91000]\n",
            " [118000]\n",
            " [270000]\n",
            " [179900]\n",
            " [142500]\n",
            " [133700]\n",
            " [167000]\n",
            " [145500]\n",
            " [284000]\n",
            " [130000]\n",
            " [123600]\n",
            " [173000]\n",
            " [187000]\n",
            " [163000]\n",
            " [132000]\n",
            " [148800]\n",
            " [137500]\n",
            " [153500]\n",
            " [185000]\n",
            " [168000]\n",
            " [192000]\n",
            " [212000]\n",
            " [108000]\n",
            " [282922]\n",
            " [222500]\n",
            " [315000]\n",
            " [173000]\n",
            " [243000]\n",
            " [179600]\n",
            " [ 93500]\n",
            " [ 84500]\n",
            " [119000]\n",
            " [151000]\n",
            " [181000]\n",
            " [201000]\n",
            " [139900]\n",
            " [165500]\n",
            " [134000]\n",
            " [167900]\n",
            " [ 89500]\n",
            " [266000]\n",
            " [129000]\n",
            " [225000]\n",
            " [172500]\n",
            " [162000]\n",
            " [151000]\n",
            " [ 84500]\n",
            " [110000]\n",
            " [104900]\n",
            " [133900]\n",
            " [369900]\n",
            " [241500]\n",
            " [137000]\n",
            " [325624]\n",
            " [272000]\n",
            " [179200]\n",
            " [150000]\n",
            " [245000]\n",
            " [143000]\n",
            " [181000]\n",
            " [200000]\n",
            " [224500]\n",
            " [244000]\n",
            " [194000]\n",
            " [227000]\n",
            " [144152]\n",
            " [176000]\n",
            " [106000]\n",
            " [ 68500]\n",
            " [162000]\n",
            " [118000]\n",
            " [239000]\n",
            " [159434]\n",
            " [240000]\n",
            " [220000]\n",
            " [112000]\n",
            " [423000]\n",
            " [173000]\n",
            " [151500]\n",
            " [386250]\n",
            " [184000]\n",
            " [120500]\n",
            " [ 39300]\n",
            " [139400]\n",
            " [105500]\n",
            " [157000]\n",
            " [215000]\n",
            " [143750]\n",
            " [140000]\n",
            " [139000]\n",
            " [171750]\n",
            " [176432]\n",
            " [139000]\n",
            " [200500]\n",
            " [110000]\n",
            " [625000]\n",
            " [143000]\n",
            " [239799]\n",
            " [ 79900]\n",
            " [140000]\n",
            " [133000]\n",
            " [126000]\n",
            " [189000]\n",
            " [175000]\n",
            " [143000]\n",
            " [187500]\n",
            " [180000]\n",
            " [167500]\n",
            " [302000]\n",
            " [325000]\n",
            " [354000]\n",
            " [107900]\n",
            " [110000]\n",
            " [286000]\n",
            " [109900]\n",
            " [190000]\n",
            " [127000]\n",
            " [229000]\n",
            " [190000]\n",
            " [134800]\n",
            " [190000]\n",
            " [153900]\n",
            " [173000]\n",
            " [255500]\n",
            " [440000]\n",
            " [281000]\n",
            " [315500]\n",
            " [204000]\n",
            " [108000]\n",
            " [138000]\n",
            " [128000]\n",
            " [157500]\n",
            " [275000]\n",
            " [207500]\n",
            " [225000]\n",
            " [160000]\n",
            " [ 76500]\n",
            " [107000]\n",
            " [110000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Row 1: Reading csv\n",
        "\n",
        "Rows 2 to 3: Split into explanatory and objective variables\n",
        "\n",
        "Row 4: Split into training data and test data"
      ],
      "metadata": {
        "id": "3zRcwH8jCp9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pretreatment (standardization)**"
      ],
      "metadata": {
        "id": "0j4x_csMCvje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_std = scaler.transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Pv6nwvPhCzL9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Load the class\n",
        "\n",
        "Line 2: Instantiation of the class\n",
        "\n",
        "Line 3: Training of the model\n",
        "\n",
        "Lines 4 to 5: Standardization (scaling to convert the mean of the features to 0 and variance to 1)"
      ],
      "metadata": {
        "id": "VES8V0XlC4RW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Learning**"
      ],
      "metadata": {
        "id": "KVDHgKJlC9VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "reg = SGDRegressor()\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi78e3npDBKx",
        "outputId": "3473ffd7-4098-461b-ea4a-73d4c2fe3968"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Load the class\n",
        "\n",
        "Line 2: Instantiation of the class\n",
        "\n",
        "Row 3: Training the model\n",
        "\n",
        "Row 4: Calculate predictions"
      ],
      "metadata": {
        "id": "60AVwddPDE--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**\n",
        "\n",
        "The previous classification question and this regression question have different evaluation indicators.\n",
        "\n",
        "The code below can be calculated simply by importing each indicator from sklearn and supplying its function with the predicted and correct values, so we will skip the detailed explanation.\n",
        "\n",
        "There are three typical indicator values as follows\n",
        "MSE is the Mean Squared Error. It is the mean of the sum of the squared values of the errors (the difference between the predicted value and the correct value, the error) for all data.\n",
        "RMSE is the square root of the aforementioned MSE, where R is the root\n",
        "√\n",
        "It is said to be easy for humans to understand because it is squared in the MSE and then restored by the root.\n",
        "r2 is the Coefficient of Determination. It is also called the contribution ratio. It is a value that indicates how well the data fits the correct answer."
      ],
      "metadata": {
        "id": "Wo-gcQH3DMCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "mse = mean_squared_error(y_test,y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "56MGaYHSDfRn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using scikit-learn, you can easily solve regression problems.\n",
        "With the library, you can easily implement complex machine learning algorithms.\n",
        "\n",
        "In machine learning, the objective variable (also known as the target variable, dependent variable, or output variable) is what the model aims to predict or classify. The type of the objective variable determines the kind of problem you're solving. Here are the main types of objective variables:\n",
        "\n",
        "Continuous:\n",
        "\n",
        "Definition: A continuous objective variable can take an infinite number of values within a range. These are typically numerical values.\n",
        "Example Problems: Regression tasks.\n",
        "Example Variables: House prices, temperature, weight, height, etc.\n",
        "Categorical:\n",
        "\n",
        "Definition: A categorical objective variable can take on a limited, fixed number of possible values, representing different categories or groups.\n",
        "Example Problems: Classification tasks.\n",
        "Example Variables: Species of plants, types of diseases, customer segments, etc.\n",
        "Ordinal:\n",
        "\n",
        "Definition: An ordinal objective variable has ordered categories, but the intervals between the categories are not necessarily equal.\n",
        "Example Problems: Ordinal regression tasks.\n",
        "Example Variables: Ratings (poor, average, good, excellent), ranks (1st, 2nd, 3rd), education levels (high school, bachelor's, master's, PhD), etc.\n",
        "Binary:\n",
        "\n",
        "Definition: A special case of categorical variables with only two possible values.\n",
        "Example Problems: Binary classification tasks.\n",
        "Example Variables: Yes/No, True/False, Success/Failure, etc.\n",
        "Multiclass:\n",
        "\n",
        "Definition: A categorical variable with more than two categories.\n",
        "Example Problems: Multiclass classification tasks.\n",
        "Example Variables: Animal species (dog, cat, bird), types of flowers (setosa, versicolor, virginica), etc.\n",
        "\n",
        "\n",
        "Key Considerations\n",
        "Problem Type: The type of objective variable directly influences the choice of machine learning algorithms and evaluation metrics.\n",
        "\n",
        "Continuous → Regression algorithms (e.g., Linear Regression, Random Forest Regressor)\n",
        "Categorical → Classification algorithms (e.g., Logistic Regression, Decision Trees, Random Forest Classifier)\n",
        "Ordinal → Ordinal regression models (e.g., Proportional Odds Model)\n",
        "Binary → Binary classification algorithms (e.g., Logistic Regression, Support Vector Machine)\n",
        "Multiclass → Multiclass classification algorithms (e.g., Multinomial Logistic Regression, Random Forest Classifier)\n",
        "Evaluation Metrics: Different types of objective variables require different evaluation metrics.\n",
        "\n",
        "Continuous → Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-squared\n",
        "Categorical → Accuracy, Precision, Recall, F1 Score, Confusion Matrix\n",
        "Ordinal → Mean Absolute Error (MAE) for ordered categories, custom metrics for ordinal classification\n",
        "Binary → ROC-AUC, Precision, Recall, F1 Score, Confusion Matrix\n",
        "Multiclass → Macro/Micro-averaged Precision, Recall, F1 Score, Confusion Matrix\n",
        "Understanding the type of your objective variable is crucial for selecting the appropriate machine learning model, preprocessing steps, and evaluation criteria."
      ],
      "metadata": {
        "id": "18QOySupDk63"
      }
    }
  ]
}