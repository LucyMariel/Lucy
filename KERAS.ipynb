{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+GDuPeGqTubpwTWG5xVAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucyMariel/Lucy/blob/master/KERAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction to Keras**"
      ],
      "metadata": {
        "id": "2DKX6jZw-_Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras is a high-level, deep learning API developed by Google for implementing neural networks. It is written in Python and is used to make the implementation of neural networks easy. It also supports multiple backend neural network computation.\n",
        "\n",
        "Keras was originally a library that appeared as a wrapper that made it easier to handle multiple frameworks such as Theano and TensorFLow, but later it was used as a high-level API for TensorFLow.\n",
        "\n",
        "We will mainly use tf.keras, which is Keras included in TensorFLow.\n",
        "\n",
        "<< What is a wrapper >>\n",
        "\n",
        "Wrappers take advantage of the functionality of the original program to provide something easier to use. TensorFlow provides the ability to efficiently perform the calculations required for neural networks, but in the early days it was time-consuming to build and train models. That's why Keras, which wraps TensorFlow to make it easier to handle, has arrived.\n",
        "\n",
        "<< What is a high-level API? >>\n",
        "\n",
        "A high-level API is created so that functions can be easily handled in large units. As an antonym, there is a low-level API that allows you to tweak functions in small units, but it is difficult to handle.\n",
        "\n",
        "In TensorFlow itself, high-level APIs are being enhanced to facilitate model construction and learning of neural networks. tf.Keras is one of them."
      ],
      "metadata": {
        "id": "a2eGB_mlAdMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Implementation of logistic regression\n",
        "\n",
        "Let's create an AND gate by logistic regression as in the introduction to TensorFLow 2.\n",
        "\n",
        "First, prepare the AND gate data."
      ],
      "metadata": {
        "id": "1GYkOWIzJAqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# ANDゲートの学習データを用意\n",
        "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y_train = np.array([[0],[0],[0],[1]])"
      ],
      "metadata": {
        "id": "2jwvmMVwJKct"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple description methods\n",
        "\n",
        "Keras makes it easy to write neural networks. There are two ways to write it: Sequential model and Functional API. Let's look at each."
      ],
      "metadata": {
        "id": "KK05GbnMKAMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential model\n",
        "\n",
        "This is a description method using the Sequential class.\n",
        "\n",
        "tf.keras.models.Sequential | TensorFlow\n",
        "\n",
        "Define the model by passing an instance of the layer in a list to the constructor of the Sequential class. The layer classes are organized on the following pages.\n",
        "\n",
        "Module: tf.keras.layers | TensorFlow\n",
        "\n",
        "To make a logistic regression, we use the fully connected layer class, tf.keras.layers.Dense. Enter the number of output units, activation function, and number of input units as arguments."
      ],
      "metadata": {
        "id": "r0xTP_JKKJPC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZtwdeXqU93dI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(2,))])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dense class can also specify the weight initialization method, bias presence / absence, etc. with arguments.\n",
        "\n",
        "tf.keras.layers.Dense | TensorFlow\n",
        "\n",
        "You can check the structure of the created model with the summary method. The output shape and the number of parameters for each layer are also listed."
      ],
      "metadata": {
        "id": "w8Nu5e5BKeEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyU7VZNPKo29",
        "outputId": "6fcbb655-3e0f-4c75-a242-f931361f0922"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3 (12.00 Byte)\n",
            "Trainable params: 3 (12.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have written the structure, compile the model. Specify the loss function, optimization method, and evaluation function at compile time. The loss function is named as a string. Here, it is binary_crossentropy because it is a binary classification. For multi-valued classification it is categorical_crossentropy, for regression it is mean_squared_error."
      ],
      "metadata": {
        "id": "cyqs1cbELL2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "iLO7WQmkLRB9",
        "outputId": "79f085c1-b4de-416b-d33a-501e688187d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e8c14e0cb99e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[0;32m----> 2\u001b[0;31m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we will learn. It is designed to use the fit method as well as scikit-learn. **verbose is a parameter of the learning process visualization method, and the default 1 is to display a progress bar that is updated on a batch-by-batch basis. If verbose is 0, it will not be displayed, and if it is 2, it will be displayed for each epoch**."
      ],
      "metadata": {
        "id": "9HSd-t5eLtWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=1,\n",
        "                    epochs=1000,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "ei57cF4QL0Q2",
        "outputId": "a94f45a2-e26d-4705-c825-92de5f04770c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-055ecbd783f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     verbose=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3981\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3984\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although it is not prepared now, if there is verification data, it is possible to verify each epoch by giving it to the argument validation_data."
      ],
      "metadata": {
        "id": "TJ1pLTbUL55v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=1,\n",
        "                    epochs=1000,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_train, y_train))"
      ],
      "metadata": {
        "id": "yNzEn9leMAVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimating uses the predict method as well as scikit-learn."
      ],
      "metadata": {
        "id": "lVVLxUNfMD8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.predict(x_train)[:, 0]\n",
        "\n",
        "# 確率を0, 1に変換\n",
        "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
        "\n",
        "print(\"y_pred_proba\", y_pred_proba)\n",
        "print(\"y_pred\", y_pred)"
      ],
      "metadata": {
        "id": "FQMGdO3tMLnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluate method is also useful if you don't need the results and just want to evaluate."
      ],
      "metadata": {
        "id": "aEt-qlwOMO-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train loss:', score[0])\n",
        "print('Train accuracy:', score[1])"
      ],
      "metadata": {
        "id": "wk7n9Ey-MUWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another way to write a Sequential model**\n",
        "In the Sequential model, it is also common to write using the add method instead of passing the layer class in the constructor."
      ],
      "metadata": {
        "id": "VD_r2ms2Ma-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(2,)))"
      ],
      "metadata": {
        "id": "u251zhjWMdXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case of a two-layer neural network instead of logistic regression, it can be described as follows. It is not necessary to give input_shape for the second and subsequent layers. This is because tf.keras calculates it automatically."
      ],
      "metadata": {
        "id": "mSD0f4iVMg4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(10, activation = tf.nn.relu, input_shape=(2,)),\n",
        "            tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)])"
      ],
      "metadata": {
        "id": "xvOk-bp-Mswt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you use the add method, it will look like this:"
      ],
      "metadata": {
        "id": "ahup6GzBMwTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, activation = tf.nn.relu, input_shape=(2,)))\n",
        "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))"
      ],
      "metadata": {
        "id": "WPB90G-hMzmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Functional API\n",
        "You can build a model with a higher degree of freedom by using the Functional API. Use the Model class instead of the Sequential class.\n",
        "\n",
        "tf.keras.models.Model | TensorFlow\n",
        "\n",
        "Describe the flow from input to output, and finally pass the input layer and the instance of the output layer to the Model class."
      ],
      "metadata": {
        "id": "NfmAbOnPM7PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.keras.layers.Input(shape=(2,)) # 入力層\n",
        "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(input_data) # output層\n",
        "\n",
        "model = tf.keras.Model(inputs=input_data, outputs=output)"
      ],
      "metadata": {
        "id": "k_T362XbOD25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After describing the model structure, it is exactly the same as the Sequential model."
      ],
      "metadata": {
        "id": "YEM6i79TO7em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=1,\n",
        "                    epochs=1000,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "udHNqTclO_Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiple layers\n",
        "A 4-layer neural network can be described as follows."
      ],
      "metadata": {
        "id": "OPdDIhKbPFUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.keras.layers.Input(shape=(2,))\n",
        "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
        "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
        "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
        "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
        "model = tf.keras.Model(inputs=input_data, outputs=output)"
      ],
      "metadata": {
        "id": "2gpeu719PIy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This description method can also express branching. The following is an example of branching into two in the third layer and joining in the next layer.\n",
        "Link: tf.keras.layers.concatenate | TensorFlow"
      ],
      "metadata": {
        "id": "HEPSBwqaPPt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.keras.layers.Input(shape=(2,))\n",
        "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
        "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
        "y1 = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
        "y2 = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
        "z = tf.keras.layers.concatenate([y1, y2])\n",
        "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(z)\n",
        "model = tf.keras.Model(inputs=input_data, outputs=output)"
      ],
      "metadata": {
        "id": "aZwri8K0PQ-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras as a wrapper\n",
        "Keras as a wrapper also uses TensorFlow as the backend by default, so the basic usage is the same.\n",
        "\n",
        "The document is also published in Japanese, so you can refer to it when using tf.keras. For example, the following page describes the two description methods.\n",
        "\n",
        "Link: Sequential Model Guide-Keras Documentation\n",
        "\n",
        "Linf: Functional API Guide-Keras Documentation\n",
        "\n",
        "The loss functions that can be specified with the compile method are also grouped together.\n",
        "\n",
        "Link: Loss function-Keras Documentation\n",
        "\n",
        "The Sequential model can be written as: An example of logistic regression.\n",
        "\n",
        "Most of the code below is essentially the same as tf.keras introduced above, but for example the activation function is passed as a separate class from the fully connected layer. Also, the optimization method part has changed from tf.train.AdamOptimizer to keras.optimizers.Adam. This is because tf.keras calls the optimization method class of TensorFlow itself, while Keras uses Keras's own optimization method class. I often see Keras code as a wrapper, so it's a good idea to get used to the slight differences."
      ],
      "metadata": {
        "id": "tU2dDBLCQ8gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_shape=(2,)))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=0.01),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=1,\n",
        "                    epochs=1000,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "cgEOTD4XRKK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 1] Sharing and executing the official tutorial model\n",
        "Please share and execute the official tutorial model of TensorFLow.\n",
        "\n",
        "Link: models/tutorials at master · tensorflow/models"
      ],
      "metadata": {
        "id": "r8iU20qZyYEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 2] (Advance assignment) Execute various methods\n",
        "The GitHub repositories of TensorFLow and Google AI Research have a wide variety of code from classic models to the latest models. Select the one you are interested in and execute it.\n",
        "\n",
        "Please note that these codes are not for beginners and may not be easy to execute, such as when you need to download a huge dataset. In that case, please do a code reading."
      ],
      "metadata": {
        "id": "AHr-L7Gdy6e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Lynk: models/research at master · tensorflow/models\n",
        "\n",
        "Lynk: google-research/google-research: Google AI Research\n",
        "\n",
        "Those with older update dates may have older versions of Python and TensorFlow and may be unwieldy. It is recommended to look at the newest ones first."
      ],
      "metadata": {
        "id": "a7hmMXxKzCST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rewriting to a different framework\n",
        "\n",
        "We will change the code of TensorFLow that handles 4 types of data sets created with \"Sprint 13 TensorFlow\" to a different framework.\n",
        "\n",
        "- Iris (binary classification only for Iris-versicolor and Iris-virginica)\n",
        "- Iris (multi-value classification using all three objective variables)\n",
        "- House Prices\n",
        "- MNIST\n",
        "\n",
        "Rewriting to Keras\n",
        "\n",
        "For Keras, use the tf.keras module included in TensorFLow.\n",
        "\n",
        "There are various types of writing in Keras such as Sequential model or Functional API, but this is not specified.\n",
        "\n"
      ],
      "metadata": {
        "id": "7OVw21qTzo3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 3] Learning Iris (binary classification) with Keras\n",
        "\n",
        "Rewrite the binary classification for the Iris dataset by TensorFlow to Keras."
      ],
      "metadata": {
        "id": "tC3RoUQW0BbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 4] Learn Iris (multi-level classification) with Keras\n",
        "\n",
        "Rewrite the ternary classification for Iris dataset by TensorFlow to Keras."
      ],
      "metadata": {
        "id": "gEvDAnLO0FyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zAGL5kgb0Ly2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 5] Learning House Prices with Keras\n",
        "\n",
        "Rewrite the regression on the House Prices data set by TensorFlow to Keras."
      ],
      "metadata": {
        "id": "J3ZfYHiV0PPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 6] Learning MNIST with Keras\n",
        "\n",
        "Please rewrite the multi-valued classification of images by MNIST dataset by TensorFlow to Keras."
      ],
      "metadata": {
        "id": "SjUJzmpN0Raw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 7] (Advance assignment) Rewriting to PyTorch\n",
        "\n",
        "Please rewrite 4 kinds of problems to PyTorch.\n",
        "\n",
        "Link: pytorch:tutorials"
      ],
      "metadata": {
        "id": "hOxHeQJy0W4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 8] (Advance assignment) Comparison of frameworks\n",
        "\n",
        "Please summarize the differences between the frameworks.\n",
        "\n",
        "<Example of viewpoint>\n",
        "\n",
        "- Calculation speed\n",
        "- Number of lines of code and readability\n",
        "- Functions provided"
      ],
      "metadata": {
        "id": "zDRr1Yd_0cF0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKzFuXjnRKIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}