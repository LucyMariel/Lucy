{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeKYbRoL12K+buOi3Yyh/D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucyMariel/Lucy/blob/master/CNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is CNN2 (two-dimensional convolutional neural network)?**\n",
        "\n",
        "Purpose\n",
        "Understand the mathematical knowledge of convolutional neural networks.\n",
        "More in-depth tips for scratch implementation of convolutional neural networks are provided, so that you can scratch implement them.\n",
        "How to learn\n",
        "Let's go through it in light of the table of contents in \"Assignments.\"\n",
        "The basic idea is the same as the previous unit, CNN1.It is possible to learn from either of them.\n",
        "Of course, it is considered easier to understand if you learn from CNN1, since there are less complicated parts."
      ],
      "metadata": {
        "id": "KUlMS0QAH-4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is convolutional neural network?\n",
        "\n",
        "Convolutional Neural Networks are called Convolutional Neural Networks (CNN). It is used to detect and classify objects in an image.\n",
        "\n",
        "We have learned that so-called normal NNs are also algorithms designed to mimic human neural circuits, but\n",
        "CNNs are also modeled on human vision.\n",
        "\n",
        " Human Visual Processing Flow​ ​\n",
        "\n",
        "Light reflected from an object projects an image onto the retina at the back of the eye.\n",
        "Instead of grasping the entire image of an object at once, it recognizes that the image is scanned for each limited area. This limited area is called the \"local receptive field\".\n",
        "A myriad of simple-type cells that recognize certain simple shapes interact with each other to recognize objects of complex shapes.\n",
        "Complex cells, which recognize the entire space, spatially complement the recognition results of simple cells\n",
        " CNN visual processing flow\n",
        "\n",
        "The flow is the same as the flow of human visual processing, with the following correspondences for each.\n",
        "\n",
        "Simple type cell: convolution layer\n",
        "\n",
        "Complex-type cells: Pooling layer\n",
        "\n",
        "Simple and complex cells act in combination with many cells by means of filters that act to expand the folding and pooling layers into multiple cells.\n",
        "\n",
        "This convolution layer, pooling layer, and filter will be explained in detail in the next section."
      ],
      "metadata": {
        "id": "NQseL0oUISVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "CNN combines convolutional and pooling layers for processing"
      ],
      "metadata": {
        "id": "SWIvPRvSIZKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution layer of CNN2\n",
        "\n",
        "purpose\n",
        "Understand how to compute two-dimensional convolutional layers\n",
        "CNN is mainly used in image recognition first. In a previous text, we mentioned 1D convolutional neural networks, and this time, it is a convolutional neural network extended to 2 dimensions. However, the basic idea is the same. Now, I will explain it by looking at the illustration of convolutional and pooling layers.\n",
        "\n",
        "As an example, consider the following black-and-white image. This black-and-white image is replaced with numerical data as shown on the right. Then, operations are performed using the filters [[1,2],[3,4]].\n",
        "\n",
        "Folding layer\n",
        "\n",
        "A \"weight\" called a kernel (filter) is given to the input value, and the result of the sum-of-products operation is passed to the next layer. Consider the convolution operation with stride 1 and padding 0. Since the stride is 1, the result of the first-stage operation is shown below. The range to which the filter is applied is shifted one by one.\n",
        "\n",
        "padding\n",
        "\n",
        "The convolution process seen above has the problem that data at the edges are neglected in the network (fewer operations are required) and the size of the data decreases as the layers get deeper.\n",
        "For this reason, convolution is sometimes performed by giving pseudo data (e.g., 0) around the input data. This pseudo data is called Padding. The example below is a calculation example in which zeros are given at both ends of the data. In this case, one 0 is given at a time, so it is called 0 padding 1If two zeros are given, it is called 0 padding 2.\n",
        "\n",
        "stride\n",
        "\n",
        "The interval value at which to apply the filter at what interval is called the stride. The size of the output data varies depending on the stride value. Below is an example of stride 2.\n",
        "\n",
        "First, the calculation for the first step is that for stride 1, we shifted them one at a time, but for stride 2, we shifted them two at a time.\n",
        "\n"
      ],
      "metadata": {
        "id": "WJcCTOa3I-Ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning\n",
        "Learning a CNN network involves updating the kernel and bias values. The updating method is similar to that of a regular neural network, as we have already learned.\n",
        "\n",
        "Summary\n",
        "\n",
        "The convolution layer changes the shape of the output depending on the number of padding strides"
      ],
      "metadata": {
        "id": "4H0E1RMXKZE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pooling layer of CNN2**\n",
        "\n",
        "purpose\n",
        "Understand how to compute pooling layers in two dimensions"
      ],
      "metadata": {
        "id": "x1BHzG2rKszm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a pooling layer?\n",
        "The process of taking a representative value such as the maximum value is called pooling.\n",
        "Pooling has the following purposes and benefits\n",
        "\n",
        "The model is more resistant to variability and distortion (because we get the main features and filter out all the noise)\n",
        "Dimensions and computational complexity can be reduced.\n",
        "Fewer parameters reduce over-learning (overfitting)\n",
        "In addition to maximum value pooling, there is also average value pooling, etc., but maximum value is the most common. Below is an example of kernel size 2 x 2 and stride 1. Increasing the stride reduces the size of the output."
      ],
      "metadata": {
        "id": "NwZ1zUa0LDpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "\n",
        "Pooling layer is sandwiched after the convolution layer\n",
        "Pushing a pooling layer in between makes for a robust model."
      ],
      "metadata": {
        "id": "yZMTSP-oLM4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kernel and channels of CNN2**\n",
        "\n",
        "purpose\n",
        "Understanding the relationship with CNN\n",
        "\n",
        "A kernel is a feature detector.\n",
        "\n",
        "Kernels have been used in the convolutional computation, and a number of different types of these kernels can be prepared. In ordinary image recognition, kernels with various initial values are generated, and these values are updated through training to create a network that can handle complex problems. The number of kernels is expressed as the number of kernels.\n",
        "\n",
        "The following is an example of the operation when the number of kernels is 2."
      ],
      "metadata": {
        "id": "8iNBM5W6LjT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a channel?\n",
        "Image data is. It is a three-dimensional composition of length x width x depth.\n",
        "The length x width is easy to imagine since it is just as you see it, but what is the depth?\n",
        "\n",
        "In fact, image data is represented by a combination of three colors, as called the three primary colors (RGB),\n",
        "and numerically speaking, the data consists of three colors for a single image.\n",
        "\n",
        "This three-color configuration is called depth and is generally referred to as a channel.\n",
        "\n",
        "The number of channels 3 is for color images (RGB images), and the number of channels is 1 for so-called black-and-white images, which are called grayscale.\n",
        "This is because black and white is represented by shades of black, not by two colors, white and black.\n",
        "\n",
        "Imagine, if you will, that there is a difference in the amount of recognition when a human being sees a black and white photo and a color photo. I don't think that just because it is a black and white photo, it does not mean that we cannot recognize buildings or automobiles.\n",
        "\n",
        "The same is true for CNNs, which in most cases use grayscale images (with 1 channel) as input values unless the color is meaningful. The advantage of using grayscale images as input values is not only that there is no difference in recognition accuracy, but also that the process is simpler and requires less computation.\n",
        "\n",
        "Use color images when color is meaningful, for example, when recognizing stained cancer cells.\n",
        "\n",
        "The following is an example of calculation when a 3-channel image is input."
      ],
      "metadata": {
        "id": "Czc3OagdMEo2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6OORdluH4Ds"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operation Process Flow\n",
        "Apply a filter to each channel of rgb and perform a sum-of-products operation\n",
        "The sum of the results of the sum-of-products operation for each channel is the final output value\n",
        "5. Summary\n",
        "The number of kernels represents the number of kernels used in the operation, and the number of channels after the operation is equal to the number of kernels"
      ],
      "metadata": {
        "id": "jiJmJZ1DMWqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the convolution layer of CNN2**"
      ],
      "metadata": {
        "id": "Au0kaEvuM9C-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "purpose\n",
        "Using Python to implement a two-dimensional convolutional layer\n",
        "\n",
        "2D convolutional layer implementation\n",
        "Below is sample code for a 2D convolutional layer that we will implement in the future.\n",
        "\n",
        "The basic structure is as follows\n",
        "\n",
        "__init__(constructor): Initialization of filter and bias values\n",
        "output_shape2d: Output size calculation\n",
        "forward (forward propagation): sum-of-products operation on the convolution layer\n",
        "backward(back propagation): Back propagation process in the convolution layer"
      ],
      "metadata": {
        "id": "IFdaU07fM-1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Definition and Constructor Implementation"
      ],
      "metadata": {
        "id": "v6L2KycRNPmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleConv2d():\n",
        "    def __init__(self, F, C, FH, FW, P, S,initializer=None,optimizer=None,activation=None):\n",
        "        self.P = P\n",
        "        self.S = S\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        self.W = self.initializer.W(F,C,FH,FW)\n",
        "        self.B = self.initializer.B(F)"
      ],
      "metadata": {
        "id": "0cykVHwPNQeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Class definition\n",
        "Line 2: Constructor definition. It takes as arguments: number of filters F, number of channels C, filter height FH, filter width FW, number of paddings P, number of strides S, initialization instance initializer, optimization method instance optimizer, and activation function instance activation.\n",
        "Lines 3 to 9: Conversion of arguments into member variables\n",
        "\n",
        "Here is the code for the class of initialization instance initializer."
      ],
      "metadata": {
        "id": "WaRq5o9FNVvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializerConv2d:\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "    def W(self, F, C, FH, FW):\n",
        "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
        "    def B(self, F):\n",
        "        return np.zeros(F)"
      ],
      "metadata": {
        "id": "6KctvVYfNZLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Class definition.\n",
        "Line 2: Definition of the constructor. It takes as an argument the standard deviation sigma of the Gaussian distribution.\n",
        "Line 3: Member variable of the standard deviation sigma of the Gaussian distribution.\n",
        "Line 4: Define initialization function W for weight W. It takes as arguments the number of filters F, the number of channels C, the height of the filter FH, and the width of the filter FW.\n",
        "Line 5: Arguments are put into np.random.randn to generate weights of arbitrary form, multiplied by sigma, and returned as the return value\n",
        "Line 6: Definition of the initialization function B for bias B. It takes as argument the number of filters F\n",
        "Line 7: Argument in np.zeros, generates arbitrary form of bias, applies sigma, and returns\n",
        "\n",
        "For the optimization method instance optimizer and activation function instance activation, use the following (similar to the text for 1D CNN)"
      ],
      "metadata": {
        "id": "tJN8w9CHNaAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.clip(A, 0, None)\n",
        "    def backward(self, dZ):\n",
        "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        return"
      ],
      "metadata": {
        "id": "9fsBpiTWNj1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement functions for calculating output size\n",
        "Next, the SimpleInitializerConv2d class implements a function for calculating the output size during forward propagation. The formula is as follows"
      ],
      "metadata": {
        "id": "z0kaNelzNo39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
        "    OH = (H +2*PH -FH)/SH +1\n",
        "    OW = (W +2*PW -FW)/SW +1\n",
        "    return int(OH),int(OW)"
      ],
      "metadata": {
        "id": "FbLTVWtWNsXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Function definition. It takes as arguments: height H, width W, padding height PH, padding width PW, filter height FH, filter width FW, stride height SH, and stride width SW.\n",
        "Line 2: Calculation of the height of the output\n",
        "Line 3: Calculation of output width"
      ],
      "metadata": {
        "id": "IUzyC4ePNxKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of functions for forward propagation\n",
        "Next, the SimpleInitializerConv2d class implements a function for calculating forward propagation. The formula is as follows"
      ],
      "metadata": {
        "id": "DnQt30n4N1_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, X,debug=False):\n",
        "    self.X = X\n",
        "    N,C,H,W = self.X.shape\n",
        "    F,C,FH,FW = self.W.shape\n",
        "    OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
        "    self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "    A = np.zeros([N,F,OH,OW])\n",
        "    self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
        "    for n in range(N):\n",
        "        for ch in range(F):\n",
        "            for row in range(0,H,self.S):\n",
        "                for col in range(0,W,self.S):\n",
        "                    if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                        continue\n",
        "                    A[n,ch,row,col] = np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]*self.W[ch,:,:,:]) +self.B[ch]\n",
        "    if debug==True:\n",
        "        return A\n",
        "    else:\n",
        "        return  self.activation.forward(A)"
      ],
      "metadata": {
        "id": "DEyQXn-QN3E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Function definition. It takes as arguments the input array X and debug or not debug.\n",
        "Line 2: Variable member of input array X\n",
        "Line 3: Variable shape of input array X\n",
        "Line 4: Variable shape of weight W\n",
        "Line 5: Calculation of output size\n",
        "Line 6: Make various sizes into member variables as self.params\n",
        "Line 7: Initialization of return value. We will override this in the future.\n",
        " Line 8: Padding process for calculation\n",
        "Line 9: Loop over the number of batches\n",
        "Line 10: Loop by number of filters\n",
        "Line 11: Loop by height, taking into account stride\n",
        "Line 12: Loop by width, taking stride into account\n",
        "Line 13: Determine if the convolution calculation is within the range of the convolution calculation\n",
        "Line 14: If true at line 13, continue\n",
        "Line 15: Calculate the relevant element and assign the calculation result to A\n",
        "From line 16 to line 17: If debug is True, returns the value of forward propagation without passing it through the activation function\n",
        "From line 18 to line 19: If debug is false, return the value of forward propagation through the activation function"
      ],
      "metadata": {
        "id": "-WMaaFBzOBzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(self, dZ,debug=False):\n",
        "    if debug==True:\n",
        "        dA = dZ\n",
        "    else:\n",
        "        dA = self.activation.backward(dZ)\n",
        "    N,C,H,W,F,FH,FW,OH,OW = self.params\n",
        "    dZ = np.zeros(self.X_pad.shape)\n",
        "    self.dW = np.zeros(self.W.shape)\n",
        "    self.dB = np.zeros(self.B.shape)\n",
        "    for n in range(N):\n",
        "        for ch in range(F):\n",
        "            for row in range(0,H,self.S):\n",
        "                for col in range(0,W,self.S):\n",
        "                    if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                        continue\n",
        "                    dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
        "    if self.P == 0:\n",
        "        dZ = np.delete(dZ,[0,H-1],axis=2)\n",
        "        dZ = np.delete(dZ,[0,W-1],axis=3)\n",
        "    else:\n",
        "        dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
        "        dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
        "        dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "        dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "    for n in range(N):\n",
        "        for ch in range(F):\n",
        "            for row in range(OH):\n",
        "                for col in range(OW):\n",
        "                    self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "    for ch in range(F):\n",
        "        self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "    self = self.optimizer.update(self)\n",
        "    return dZ"
      ],
      "metadata": {
        "id": "5aKThcrBOJel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Definition of the function. The function receives as arguments the back-propagated value dZ and the debug or not debug.\n",
        "Lines 2 to 3: If debug is true, the back propagation of the activation function is not performed and subsequent calculations proceed.\n",
        "Lines 4 to 5: If debug is false, back propagation of the activation function is performed and subsequent calculations proceed.\n",
        "Line 6: Obtain various sizes that were made into member variables during forward propagation\n",
        "Lines 7 to 9: Initialization of return value dZ, weight dW, and bias dB (this will be overwritten). After this, return value dZ, weight dW, and bias dB are calculated in this order.\n",
        "Line 10: Loop by number of batches\n",
        "Line 11: Loop by number of filters\n",
        "Line 12: Loop by height, taking stride into account\n",
        "Line 13: Loop by width, taking stride into account\n",
        "Line 14: Determine if the convolution calculation is within the range of the convolution calculation\n",
        "Line 15: If true at line 13, continue\n",
        "Line 16: Calculate the relevant element and assign the calculation result to dZ\n",
        "Lines 17 to 24: The size of the array takes padding into account, so unnecessary portions are removed\n",
        "Line 25: Loop by the number of batches\n",
        "Line 26: Loop by number of filters\n",
        "Line 27: Loop by height\n",
        "Line 28: Loop by width\n",
        "Line 29: Calculate the relevant element and assign the result to dW\n",
        "Line 30: Loop by number of filters\n",
        "Line 31: Calculate the relevant element and assign the result to dB\n",
        "Line 32: The update function of the update method instance is executed by passing the instance confidence of the child convolution layer as an argument\n",
        "Line 33: The value of back propagation to the next layer is returned."
      ],
      "metadata": {
        "id": "hO5Q0wPMOIb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Problem 2\" Experiments on 2D convolutional layers with small arrays\n",
        "We will experiment with the following array to see if the 2D convolution layer we created works properly"
      ],
      "metadata": {
        "id": "lz_v07-9ObCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[[[ 1,  2,  3,  4],[ 5,  6,  7,  8],[ 9, 10, 11, 12],[13, 14, 15, 16]]]])\n",
        "w = np.array([[[[ 0.,  0.,  0.],[ 0.,  1.,  0.],[ 0., -1.,  0.]]],[[[ 0.,  0.,  0.],[ 0., -1.,  1.],[ 0.,  0.,  0.]]]])"
      ],
      "metadata": {
        "id": "TuaRawhvOcOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Definition of input array X\n",
        "Line 2: Definition of weight w"
      ],
      "metadata": {
        "id": "k3dnmPbKOf3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_conv_2d = SimpleConv2d(F=2, C=1, FH=3, FW=3, P=0, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(),activation=ReLU())\n",
        "simple_conv_2d.W = w\n",
        "A = simple_conv_2d.forward(x,True)\n",
        "print(A)"
      ],
      "metadata": {
        "id": "LhtVxU3qOmht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[[[[-4. -4.]\n",
        "   [-4. -4.]]\n",
        "  [[ 1.  1.]\n",
        "   [ 1.  1.]]]]"
      ],
      "metadata": {
        "id": "y6bGvSQsOqBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Instantiate the SimpleConv2d class you created\n",
        "Line 2: Overwrite the weight W with the one just defined\n",
        "Line 3: Execute the forward function of the forward propagation process\n",
        "Line 4: Print the return value A"
      ],
      "metadata": {
        "id": "PkljPuNyOs_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "da = np.array([[[[ -4,  -4], [ 10,  11]],[[  1,  -7],[  1, -11]]]])\n",
        "dZ = simple_conv_2d.backward(da,True)\n",
        "print(dZ)"
      ],
      "metadata": {
        "id": "4WDy8yxzOwbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[[[[-5.  4.]\n",
        "   [13. 27.]]]]"
      ],
      "metadata": {
        "id": "3fVdXctQOzuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Define backward propagation value da\n",
        "Line 2: Execute the backward function of the reverse process\n",
        "Line 3: Print the return value dZ"
      ],
      "metadata": {
        "id": "EjmETVvUO3Dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Problem 3\" Output size after 2D convolution\n",
        "Let's run the function to calculate the output size under the following conditions. Make sure that the output size is consistent with the output size calculated manually."
      ],
      "metadata": {
        "id": "fwE2YugKO_W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_conv_2d.output_shape2d(H=6,W=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1)"
      ],
      "metadata": {
        "id": "jMskSIQJPAbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(4, 4)"
      ],
      "metadata": {
        "id": "XLgKt51yPFDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Execution of output_shape2d function"
      ],
      "metadata": {
        "id": "X04ifm4GPJ6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "\n",
        "Implemented forward and back propagation processing of a two-dimensional convolutional neural network.\n",
        "Operation checks were performed on the various functions implemented."
      ],
      "metadata": {
        "id": "HkKZ2KCyPQq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation and smoothing of the maximum pooling layer of CNN2**"
      ],
      "metadata": {
        "id": "BuP9ndhEyRP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "purpose\n",
        "Understand how to implement the maximum pooling layer of a 2D CNN\n",
        "Understand the need for a smoothing process"
      ],
      "metadata": {
        "id": "asJk25_dyoyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formula for maximum pooling layer\n",
        "\n",
        "Create a class MaxPool2D for the maximum pooling layer. Some parts of the pooling layer are easier to understand if they are not expressed in mathematical terms, but if they are expressed in mathematical terms, the forward propagation looks like this\n",
        "\n",
        "$P_{i,j}$: A set of input array indices for output to i row and j column. Row (p) and column (q) within the range of $S_{h}×S_{w}$\n",
        "\n",
        "$S_{h}, S_{w}$: Height (h) and width (w) stride size\n",
        "\n",
        "$(p,q)\\in P_{i,j}$: Index of row (p) and column (q) included in $P_{i,j}$\n",
        "\n",
        "$a_{i,j,m}$: i-th row, j-th column, k-channel value of the output array\n",
        "\n",
        "$x_{p,q,k}$: p-by-q, k-channel value of the input array\n",
        "\n",
        "Within a certain range, the maximum value is calculated, leaving the axis in the channel direction unchanged.\n",
        "\n",
        "For backpropagation, it is necessary to retain the maximum index $(p,q)$ in forward propagation. This is because the error is sent as it is to the part that had the maximum value at the time of forward, and 0 is put in other parts.\n"
      ],
      "metadata": {
        "id": "7Tu_Yk-Ly7BP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of \"Problem 4\" Maximum Pooling Layer\n",
        "\n",
        "Let's implement the pooling layer according to the learned pooling process.\n",
        "\n",
        "The basic structure is as follows\n",
        "\n",
        "__init__(constructor): make member variables of index recording array PIndex of padding width P, value of forward propagation PA, and maximum value\n",
        "forward(forward propagation): sum-of-products operation for the largest pooling layer\n",
        "backward(back propagation): Back propagation process for the maximum pooling layer"
      ],
      "metadata": {
        "id": "SyGYAqsDztMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2D():\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None"
      ],
      "metadata": {
        "id": "RubpQOqnz14v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Definition of the maximum pooling layer class.\n",
        "Line 2: Definition of the constructor. Receives the pooling width as an argument.\n",
        "Lines 3 to 5: Padding width P, value of forward propagation PA, and index recording array PIndex of the maximum value into member variables."
      ],
      "metadata": {
        "id": "tjff-0Hs0IF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self,A):\n",
        "    N,F,OH,OW = A.shape\n",
        "    PH,PW = int(OH/self.P),int(OW/self.P)\n",
        "    self.params = N,F,OH,OW,self.P,PH,PW\n",
        "    self.PA = np.zeros([N,F,PH,PW])\n",
        "    self.Pindex = np.zeros([N,F,PH,PW])\n",
        "    for n in range(N):\n",
        "        for ch in range(F):\n",
        "            for row in range(PH):\n",
        "                for col in range(PW):\n",
        "                    self.PA[n,ch,row,col] =　np.max(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "                    self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "    return self.PA"
      ],
      "metadata": {
        "id": "Mx7Do3rB0gEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Function definition. The function receives input array A as an argument.\n",
        "Line 2: The size of the input array is summarized and made a member variable.\n",
        "\n",
        "Line 3: Calculates the number of slides on the vertical and horizontal axes\n",
        "\n",
        "Line 4: Various parameters are summarized and made into member variables.\n",
        "\n",
        "Lines 5 to 6: Initialize PA and PIndex\n",
        "\n",
        "Line 7: Loop by the number of batches\n",
        "\n",
        "Line 8: Loop by the number of filters\n",
        "\n",
        "Line 9: Number of vertical slides\n",
        "\n",
        "Line 10: Number of horizontal slides\n",
        "\n",
        "Line 11: Get and store the maximum value\n",
        "\n",
        "Line 12: Record index of maximum value\n",
        "\n",
        "Line 13: Return value of forward propagation\n"
      ],
      "metadata": {
        "id": "KsHbcPja0g7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(self,dA):\n",
        "    N,F,OH,OW,PS,PH,PW = self.params\n",
        "    dP = np.zeros([N,F,OH,OW])\n",
        "    for n in range(N):\n",
        "        for ch in range(F):\n",
        "            for row in range(PH):\n",
        "                for col in range(PW):\n",
        "                    idx = self.Pindex[n,ch,row,col]\n",
        "                    tmp = np.zeros((PS*PS))\n",
        "                    for i in range(PS*PS):\n",
        "                        if i == idx:\n",
        "                            tmp[i] = dA[n,ch,row,col]\n",
        "                        else:\n",
        "                            tmp[i] = 0\n",
        "                    dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "    return dP"
      ],
      "metadata": {
        "id": "rf_3YnZs0_T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Function definition. Receives the back-propagated value dA as an argument.\n",
        "Line 2: Obtains various parameters that have been saved.\n",
        "Line 3: Initialization of the value dP to be back propagated\n",
        "Line 4: Loop by the number of batches\n",
        "Line 5: Loop by number of filters\n",
        "Line 6: Number of vertical slides\n",
        "Line 7: Number of horizontal slides\n",
        "Line 8: Get the index from which the maximum value has been obtained\n",
        "Line 9: Temporarily stored variable for back propagation. After assigning a value to it, assign it to the value dP to be back propagated.\n",
        "Line 10: Loop with the size of MaxPooling\n",
        "Lines 11 to 12: In the case of the corresponding index, the back-propagated value is assigned as it is.\n",
        "Lines 13 to 14: If the index is not the corresponding index, 0 is assigned.\n",
        "Line 15: Assign the temporarily stored variable tmp of back propagation to the value dP to be back propagated\n",
        "Line 16: Return value"
      ],
      "metadata": {
        "id": "27ZHtMtz2IRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 6\" Smoothing\n",
        "The final output of convolution is output as the same two-dimensional data as the image.\n",
        "\n",
        "When determining what objects are in an image, for example, the output is converted to 1D and then passed through a regular NN to obtain the final output.\n",
        "\n",
        "Here, let's implement the process of converting 2D data to 1D."
      ],
      "metadata": {
        "id": "zyoTKtTa2tMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self,X):\n",
        "        self.shape = X.shape\n",
        "        return X.reshape(len(X),-1)\n",
        "    def backward(self,X):\n",
        "        return X.reshape(self.shape)"
      ],
      "metadata": {
        "id": "gNRy3xIq2unK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Definition of the smoothing class.\n",
        "Line 2: Definition of the constructor. The constructor of the smoothing class does not perform any particular processing.\n",
        "Line 3: Definition of the forward propagation function. It takes an input array X as an argument.\n",
        "Line 4: Record the shape of the input array X.\n",
        "Line 5: Perform reshape for smoothing and return\n",
        "Line 6: Receive the input array X as an argument to the back propagation function.\n",
        "Line 7: Shape and return according to the shape recorded during forward propagatio"
      ],
      "metadata": {
        "id": "tTMtnQNU24wP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MaxPooling Layer\n",
        "Purpose\n",
        "The MaxPooling layer is used to reduce the spatial dimensions (width and height) of the input volume for the next layer.\n",
        "It helps to decrease the computational load and the number of parameters, and it can also help to avoid overfitting.\n",
        "How It Works\n",
        "The MaxPooling layer applies a pooling operation to the input, typically with a small filter (e.g., 2x2) and a stride (e.g., 2).\n",
        "For each sub-region of the input, it outputs the maximum value from that region.\n",
        "\n",
        "\n",
        "Flatten Layer\n",
        "Purpose\n",
        "The Flatten layer converts the 2D matrix of features into a 1D vector.\n",
        "It prepares the data for the fully connected (dense) layers that follow the convolutional and pooling layers in a CNN.\n",
        "How It Works\n",
        "It takes the input, which is usually in the shape of a multi-dimensional array (e.g., height x width x channels), and flattens it into a single vector."
      ],
      "metadata": {
        "id": "fIqCdyd-6FVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "MaxPooling layer implemented.\n",
        "Flatten layer implemented."
      ],
      "metadata": {
        "id": "70qDIvY54GGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "**difference between CNN1 and CNN2**\n",
        "\n",
        "The terms \"CNN1\" and \"CNN2\" are not standard terminology in the context of convolutional neural networks (CNNs). However, they could refer to different versions or configurations of CNN models. Let me outline some possible differences that could be implied by these terms:\n",
        "\n",
        "1. Different Network Architectures\n",
        "\"CNN1\" and \"CNN2\" could represent CNN models with different architectures. For example:\n",
        "\n",
        "CNN1: A simpler CNN with fewer layers and filters.\n",
        "CNN2: A more complex CNN with more layers, more filters, and possibly additional types of layers (e.g., dropout, batch normalization).\n",
        "Example\n",
        "CNN1:\n",
        "\n",
        "Input layer\n",
        "Convolutional layer (32 filters, kernel size 3x3)\n",
        "Max pooling layer (pool size 2x2)\n",
        "Fully connected layer\n",
        "Output layer\n",
        "CNN2:\n",
        "\n",
        "Input layer\n",
        "Convolutional layer (64 filters, kernel size 3x3)\n",
        "Convolutional layer (64 filters, kernel size 3x3)\n",
        "Max pooling layer (pool size 2x2)\n",
        "Dropout layer (0.25 dropout rate)\n",
        "Fully connected layer\n",
        "Output layer\n",
        "2. Different Hyperparameters\n",
        "\"CNN1\" and \"CNN2\" could refer to the same CNN architecture but with different hyperparameters, such as learning rate, batch size, or number of epochs.\n",
        "\n",
        "Example\n",
        "CNN1:\n",
        "\n",
        "Learning rate: 0.001\n",
        "Batch size: 32\n",
        "Number of epochs: 10\n",
        "CNN2:\n",
        "\n",
        "Learning rate: 0.0001\n",
        "Batch size: 64\n",
        "Number of epochs: 20\n",
        "3. Different Training Data or Preprocessing\n",
        "\"CNN1\" and \"CNN2\" might be trained on different datasets or with different data preprocessing techniques.\n",
        "\n",
        "Example\n",
        "CNN1:\n",
        "\n",
        "Trained on grayscale images\n",
        "Normalized pixel values between 0 and 1\n",
        "CNN2:\n",
        "\n",
        "Trained on RGB images\n",
        "Standardized pixel values (mean 0, standard deviation 1)\n",
        "4. Different Purposes or Tasks\n",
        "\"CNN1\" and \"CNN2\" could be designed for different tasks or purposes, such as one for image classification and another for object detection.\n",
        "\n",
        "Example\n",
        "CNN1: A CNN designed for classifying handwritten digits (e.g., MNIST dataset).\n",
        "CNN2: A CNN designed for detecting objects in images (e.g., YOLO or Faster R-CNN)."
      ],
      "metadata": {
        "id": "y_IY6Lt04E94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN2 training and estimation**"
      ],
      "metadata": {
        "id": "GACGn80g6uvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "purpose\n",
        "Implement the Scratch2dCNNClassifier class\n",
        "\"Problem 7\" Learning and Estimation\n",
        "We will implement a CNN class for training.\n",
        "Using each of the layers we have created so far, let's implement the Scratch2dCNNClassifier class for 2D CNN for training and estimation."
      ],
      "metadata": {
        "id": "J_Cma1Cx60lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Classes and Constructors"
      ],
      "metadata": {
        "id": "VHG5gtrb7HIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scratch2dCNNClassifier():\n",
        "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
        "        self.NN = NN\n",
        "        self.CNN = CNN\n",
        "        self.n_epoch = n_epoch\n",
        "        self.n_batch = n_batch\n",
        "        self.verbose = verbose\n",
        "        self.log_loss = np.zeros(self.n_epoch)\n",
        "        self.log_acc = np.zeros(self.n_epoch)"
      ],
      "metadata": {
        "id": "6omZ2DLF60CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Class definition.\n",
        "Line 2: Constructor definition. The following arguments are received: NN, which is a dictionary type and stores instances of layers; CNN, which is a dictionary type and stores instances of layers; n_epoch, the number of training cycles; n_batch, the number of batches; and verbose, whether or not to output logs.\n",
        "Lines 3 to 7: Make the arguments member variables\n",
        "Lines 8 to 9: Initialize the array for logging"
      ],
      "metadata": {
        "id": "vP33B4wv7Ph_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for loss calculation and correct answer rate calculation"
      ],
      "metadata": {
        "id": "3FO9Sa7n7TiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(self,y,yt):\n",
        "    delta = 1e-7\n",
        "    return -np.mean(yt*np.log(y+delta))\n",
        "def accuracy(self,Z,Y):\n",
        "    return accuracy_score(Y,Z)"
      ],
      "metadata": {
        "id": "4xnexLIx7Q3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Definition of a function for loss calculation. It takes as arguments the predicted value y and the correct answer data yt.\n",
        "Line 2: Define a minimum value of delta as a countermeasure against infinity when calculating np.log.\n",
        "Line 3: Compute and return the cross-entropy error.\n",
        "Line 4: Define a function to calculate the percentage of correct answers. It takes as arguments the class Z of predictions and the class Y of correct answers.\n",
        "Line 5: Return the result of the accuracy_score function of sklearn."
      ],
      "metadata": {
        "id": "xG6fOERW7cQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Function"
      ],
      "metadata": {
        "id": "OGCNHoZS7gOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self, X, y, X_val=False, y_val=False):\n",
        "    for epoch in range(self.n_epoch):\n",
        "        get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
        "        self.loss = 0\n",
        "        for mini_X_train, mini_y_train in get_mini_batch:\n",
        "            forward_data = mini_X_train[:,np.newaxis,:,:]\n",
        "            for layer in range(len(self.CNN)):\n",
        "                forward_data = self.CNN[layer].forward(forward_data)\n",
        "            flt = Flatten()\n",
        "            forward_data = flt.forward(forward_data)\n",
        "            for layer in range(len(self.NN)):\n",
        "                forward_data = self.NN[layer].forward(forward_data)\n",
        "            Z = forward_data\n",
        "            backward_data = (Z - mini_y_train)/self.n_batch\n",
        "            for layer in range(len(self.NN)-1,-1,-1):\n",
        "                backward_data = self.NN[layer].backward(backward_data)\n",
        "            backward_data = flt.backward(backward_data)\n",
        "            for layer in range(len(self.CNN)-1,-1,-1):\n",
        "                backward_data = self.CNN[layer].backward(backward_data)\n",
        "            self.loss += self.loss_function(Z,mini_y_train)\n",
        "            if self.verbose:\n",
        "                print('batch loss %f'%self.loss_function(Z,mini_y_train))\n",
        "        if self.verbose:\n",
        "            print(self.loss/len(get_mini_batch),self.accuracy(self.predict(X),np.argmax(y,axis=1)))\n",
        "        self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
        "        self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))"
      ],
      "metadata": {
        "id": "mTDdKSwQ7hi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Function definition. Receives as arguments the explanatory variable X for the training data, the objective variable y for the training data, the explanatory variable X_val for the evaluation data, and the objective variable y_val for the evaluation data\n",
        "Line 2: Loop for the number of training times\n",
        "Line 3: Generate mini-batch iterator\n",
        "Line 4: Initialize total loss storage for the batch\n",
        "Line 5: Loop through mini-batch iterator\n",
        "Line 6: Transform data shape\n",
        "Line 7: Loop through convolution layer of member variables\n",
        "Line 8: Execute the forward propagation function of the convolution layer\n",
        "Line 9: Define smoothing layer\n",
        "Line 10: Execution of the forward propagation function for the smoothing layer\n",
        "Line 11: Loop through the normal layer of member variables\n",
        "Line 12: Execution of the forward propagation function for the normal layer\n",
        "Line 13: Assign the final forward propagation output forward_data to Z\n",
        "Line 14: Compute the error for back propagation\n",
        "Line 15: Loop through the normal layers of the member variables in reverse order\n",
        "Line 16: Execute the back propagation function for the normal layer\n",
        "Line 17: Execution of the back propagation function for the smoothing layer\n",
        "Line 18: Loop over convolution layers of member variables in reverse order\n",
        "Line 19: Execution of the back propagation function for the convolution layer\n",
        "Line 20: Loss calculation\n",
        "Lines 21 to 24: Output of the learning process\n",
        "Line 25: Calculate and record losses\n",
        "Line 26: Compute and record the percentage of correct answers"
      ],
      "metadata": {
        "id": "2EZ3a0X172wP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction Function"
      ],
      "metadata": {
        "id": "fvJia3pS7_5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(self, X):\n",
        "    pred_data = X[:,np.newaxis,:,:]\n",
        "    for layer in range(len(self.CNN)):\n",
        "        pred_data = self.CNN[layer].forward(pred_data)\n",
        "    pred_data = flt.forward(pred_data)\n",
        "    for layer in range(len(self.NN)):\n",
        "        pred_data = self.NN[layer].forward(pred_data)\n",
        "    return np.argmax(pred_data,axis=1)"
      ],
      "metadata": {
        "id": "4-qvKSKz8CvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Function definition. It takes an input array X as an argument.\n",
        "Line 2: Transform the data shape\n",
        "Line 3: Loop through the convolution layer of member variables\n",
        "Line 4: Execution of the forward propagation function on the convolution layer\n",
        "Line 5: Execution of the forward propagation function of the smoothing layer\n",
        "Line 6: Loop through the normal layer of member variables\n",
        "Line 7: Execution of the forward propagation function for the normal layer\n",
        "Row 8: Adopt the index with the largest value as the prediction class"
      ],
      "metadata": {
        "id": "z7UaMo4K8Gw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform learning and estimation\n",
        "Now that we have implemented the 2D CNN class, let's instantiate and run it.\n",
        "\n",
        "Layer Group Definition"
      ],
      "metadata": {
        "id": "4fvj6_m08MBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN = {\n",
        "    0:FC(1960, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "    1:FC(200, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "    2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
        "}\n",
        "CNN = {\n",
        "    0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(),activation=ReLU()),\n",
        "    1:MaxPool2D(2),\n",
        "}"
      ],
      "metadata": {
        "id": "1S2OK8448O1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Definition of NN layer group\n",
        "Lines 2 to 4: Definition of the first, second, and third layers, respectively\n",
        "Line 6: Definition of CNN layers\n",
        "Line 7: Convolution layer\n",
        "Line 8: Definition of the MaxPooling layerLine 8: Definition of the MaxPooling layer\n",
        "\n",
        "Instantiation and Learning"
      ],
      "metadata": {
        "id": "rYXZ-lhA8TC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=1,n_batch=20,verbose=True)\n",
        "cnn1.fit(X_train,y_train_one_hot)"
      ],
      "metadata": {
        "id": "6tya4G5R8ZcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Pass necessary arguments and instantiate\n",
        "Line 2: Execution of the fit function\n",
        "\n",
        "Estimated"
      ],
      "metadata": {
        "id": "XdM0hqu08aKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn1.predict(X_val)\n",
        "accuracy = accuracy_score(np.argmax(y_val,axis=1), y_pred)\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "3Q5KRWIh8c-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Execute predict function\n",
        "Line 2: Calculate ACC\n",
        "Line 3: Print the result"
      ],
      "metadata": {
        "id": "OoUXaR178hWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 10\" Calculation of output size and number of parameters\n",
        "When building a CNN model, it is necessary to pre-compute the number of features at the stage of input to the full join layer.\n",
        "\n",
        "Also, when dealing with huge models, the number of parameters becomes essential due to memory and calculation speed. The framework can show you the number of parameters in each layer, but you need to understand the meaning of the parameters to be able to adjust them appropriately.\n",
        "\n",
        "Calculate the output size and the number of parameters for the following three convolution layers. For the number of parameters, please also consider the bias term.\n",
        "\n",
        "1.\n",
        "\n",
        "Input size : 144 x 144, 3 channels\n",
        "Filter size: 3 x 3, 6 channels\n",
        "Stride : 1\n",
        "Padding: none\n",
        "2.\n",
        "\n",
        "Input size : 60x60, 24 channels\n",
        "Filter size: 3 x 3, 48 channels\n",
        "Stride : 1\n",
        "Padding: none\n",
        "3.\n",
        "\n",
        "Input size : 20x20, 10 channels\n",
        "Filter size: 3 x 3, 20 channels\n",
        "Stride: 2\n",
        "Padding: none\n",
        "The last example is a case where you can't get the convolution just right. The framework sometimes does not look at the extra pixels, so consider that when calculating. This is an example of why such a setting is not desirable, as it will result in missing edges."
      ],
      "metadata": {
        "id": "4E5AoMqf8nbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying this formula to the above problem yields the following\n",
        "\n",
        "1.\n",
        "\n",
        "Input size : 144 x 144, 3 channels\n",
        "Filter size: 3 x 3, 6 channels\n",
        "Stride : 1\n",
        "Padding: none\n",
        "→ Output size: 6 x 142 x 142\n",
        "\n",
        "→ Number of parameters (weights) (F x C x FH x FW): 162\n",
        "\n",
        "→ Number of parameters (bias) (F): 6\n",
        "\n",
        "2.\n",
        "\n",
        "Input size : 60x60, 24 channels\n",
        "Filter size: 3 x 3, 48 channels\n",
        "Stride : 1\n",
        "Padding: none\n",
        "→ Output size: 48 x 58 x 58\n",
        "\n",
        "→ Number of parameters (weights) (F x C x FH x FW): 10368\n",
        "\n",
        "→ Number of parameters (bias) (F): 48\n",
        "\n",
        "3.\n",
        "\n",
        "Input size : 20x20, 10 channels\n",
        "Filter size: 3 x 3, 20 channels\n",
        "Stride: 2\n",
        "Padding: none\n",
        "→ Output size: 20x9x9\n",
        "\n",
        "→ Number of parameters (weights) (F x C x FH x FW): 1800\n",
        "\n",
        "→ Number of parameters (bias) (F): 20\n",
        "\n",
        "5. Summary\n",
        "2D CNN classes were implemented, trained and estimated\n",
        "Calculated with respect to the number of parameters required for the calculation based on the NN measure of computational complexity."
      ],
      "metadata": {
        "id": "irsk_wyA8zLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SimpleConv2d**"
      ],
      "metadata": {
        "id": "ryXEkZ0IP-DR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this Sprint\n",
        "Understanding the basics of CNNs through Scratch\n",
        "How to learn\n",
        "After implementing a convolutional neural network for 2D in scratch, we will train and validate it."
      ],
      "metadata": {
        "id": "gnN0QO4WP_-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2D Scratch Convolutional Neural Network\n",
        "We will build from scratch a class of convolutional neural networks (CNNs) for 2D, implementing the algorithms using only minimal libraries such as NumPy.\n",
        "\n",
        "We will also create a pooling layer and so on to complete the basic form of the CNN. The name of the class should be Scratch2dCNNClassifier.\n",
        "\n",
        "Preparing the dataset\n",
        "We continue to use the MNIST dataset, entering the 2D convolutional layer in a 28x28 state.\n",
        "\n",
        "In this case, there is only one channel because it is a black and white image, but the axis in the channel direction must be prepared.\n",
        "\n",
        "(n_samples, n_channels, height, width)in the form of eitherNCHWor(n_samples, height, width, n_channels)in the form ofNHWC."
      ],
      "metadata": {
        "id": "GmRBdFTCQNKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1】Creating a 2-D convolutional layer\n",
        "Develop the class Conv1d for 1D convolutional layers and create the class Conv2d for 2D convolutional layers.\n",
        "\n",
        "The formula for forward propagation is as follows\n",
        "\n",
        "$a_{i,j,m}$: i-th row, j-th column, m-channel value of the output array\n",
        "\n",
        "$i$: Array row index\n",
        "\n",
        "$j$: the column index of the array\n",
        "\n",
        "$m$: Output channel index\n",
        "\n",
        "$K$: Number of input channels\n",
        "\n",
        "$F_{h}, F_{w}$: Filter size in height (h) and width (w)\n",
        "\n",
        "$x_{(i+s),(j+t),k}$: (i+s) row (j+t) column, k channel value of the input array\n",
        "\n",
        "$w_{s,t,k,m}$: sth and tth column of the weight array. Weight to be output to the m channel for the input of the k channel\n",
        "\n",
        "$b_m$: Bias term of output to m channel\n",
        "\n",
        "All are scalars.\n",
        "\n",
        "Next is the update formula, which has the same form as for 1D convolutional and all-combining layers.\n"
      ],
      "metadata": {
        "id": "doeX18bsTBeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 2] Experiments with 2D convolutional layers on small arrays\n",
        "Check if forward propagation and back propagation are performed correctly with the small sequence shown below.\n",
        "\n",
        "Input x, weight w as follows."
      ],
      "metadata": {
        "id": "1xj_YasaUImR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN2 のフォワードを流す時の入力データ\n",
        "# (1,1,4,4)\n",
        "x = np.array([[[[ 1,  2,  3,  4],\n",
        "                [ 5,  6,  7,  8],\n",
        "                [ 9, 10, 11, 12],\n",
        "                [13, 14, 15, 16]]]])\n",
        "\n",
        "# (2,3,3)\n",
        "w = np.array([[[ 0.,  0.,  0.],\n",
        "               [ 0.,  1.,  0.],\n",
        "               [ 0., -1.,  0.]],\n",
        "\n",
        "              [[ 0.,  0.,  0.],\n",
        "               [ 0., -1.,  1.],\n",
        "               [ 0.,  0.,  0.]]])"
      ],
      "metadata": {
        "id": "vNz73v-hULjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After forward propagation, the output is as follows."
      ],
      "metadata": {
        "id": "3vc3nx2vUOgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array([[[-4, -4],\n",
        "        [-4, -4]],\n",
        "\n",
        "       [[ 1,  1],\n",
        "        [ 1,  1]]])"
      ],
      "metadata": {
        "id": "zwRGeT6ZURfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, consider backpropagation. If the error is:"
      ],
      "metadata": {
        "id": "jwduS6enUSeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (?,1,2,2,)\n",
        "delta = np.array([[[ -4,  -4],\n",
        "                   [ 10,  11]],\n",
        "\n",
        "                  [[  1,  -7],\n",
        "                   [  1, -11]]])"
      ],
      "metadata": {
        "id": "tRNkc0lrUVRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation gives the following values. If there is padding, the output will be:"
      ],
      "metadata": {
        "id": "gFrqU10cUbsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array([[-5,  4],\n",
        "       [13, 27]])"
      ],
      "metadata": {
        "id": "BQicVvdrUfV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 3] Output size after 2-dimensional convolution\n",
        "The convolution changes the size of the feature map. The formula below will tell you how it changes. Create a function to do this calculation."
      ],
      "metadata": {
        "id": "zc7ECfKQUlAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$N_{out}$: Output size (number of features)\n",
        "\n",
        "$N_{in}$: Input size (number of features)\n",
        "\n",
        "$P$: Number of paddings in one direction\n",
        "\n",
        "$F$: Filter size\n",
        "\n",
        "$S$: Stride size\n",
        "\n",
        "$h$ is the height direction, $w$ is the width direction\n",
        "\n",
        "[Problem 4] Creation of maximum pooling layer\n",
        "Create a class MaxPool2D for the maximum pooling layer. Some parts of the pooling layer are easier to understand if they are not expressed in mathematical terms, but if they are expressed in mathematical terms, the forward propagation looks like this\n",
        "\n",
        "a\n",
        "i\n",
        ",\n",
        "j\n",
        ",\n",
        "K\n",
        "=\n",
        "max\n",
        "(\n",
        "p\n",
        ",\n",
        "q\n",
        ")\n",
        "∈\n",
        "P\n",
        "i\n",
        ",\n",
        "j\n",
        "\n",
        "x\n",
        "p\n",
        ",\n",
        "q\n",
        ",\n",
        "K\n",
        "$P_{i,j}$: A set of input array indices for output to i row and j column. Row (p) and column (q) within the range of $S_{h}×S_{w}$\n",
        "\n",
        "$S_{h}, S_{w}$: Height (h) and width (w) stride size\n",
        "\n",
        "$(p,q)\\in P_{i,j}$: Index of row (p) and column (q) included in $P_{i,j}$\n",
        "\n",
        "$a_{i,j,m}$: i-th row, j-th column, k-channel value of the output array\n",
        "\n",
        "$x_{p,q,k}$: p-by-q, k-channel value of the input array\n",
        "\n",
        "Within a certain range, the maximum value is calculated, leaving the axis in the channel direction unchanged.\n",
        "\n",
        "For backpropagation, it is necessary to retain the maximum index $(p,q)$ in forward propagation. This is because the error is sent as it is to the part that had the maximum value at the time of forward, and 0 is put in other parts.\n",
        "\n",
        "[Problem 5] (Advance task) Creating average pooling\n",
        "Create a class AveragePool2D for the average pooling layer.\n",
        "\n",
        "This is a pooling layer where the output is an average value rather than the maximum value in a range.\n",
        "\n",
        "In image recognition, the maximum pooling layer is commonly used, while the average pooling is less commonly used.\n",
        "\n",
        "[Problem 6] Smoothing\n",
        "Create a Flatten class for smoothing.\n",
        "\n",
        "In the forward direction, the three dimensions of channel, height and width are reshaped to one dimension. The values are recorded and reshaped again in the backward direction.\n",
        "\n",
        "By interposing this class of smoothing, we can create an array suitable for all the combined layers before the output.\n",
        "\n",
        "3. Verification\n",
        "[Problem 7] Learning and estimation\n",
        "Use the created Conv2d to train and estimate MNIST and calculate the Accuracy.\n",
        "\n",
        "Aim to move first, even if the accuracy is low.\n",
        "\n",
        "[Problem 8] (Advance assignment) LeNet\n",
        "When performing image recognition with CNNs, it is common to use well-known structures instead of considering filter size and number of layers from scratch. The most historically important one is LeNet from 1998, although it is no longer in practical use today. You can reproduce this structure and run it against MNIST to calculate the Accuracy.\n",
        "\n",
        "Link: Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998."
      ],
      "metadata": {
        "id": "jzLpIqi5U985"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subsampling is the modern equivalent of pooling. Let's make a modern version of it as follows. The activation function was also a sigmoid function back then, but we'll call it ReLU.\n",
        "\n",
        "Convolutional layer Number of output channels 6, filter size 5 x 5, stride 1\n",
        "ReLU\n",
        "Maximum pooling\n",
        "Convolutional layer 16 output channels, filter size 5 x 5, stride 1\n",
        "ReLU\n",
        "Maximum pooling\n",
        "smoothing\n",
        "All coupling layers 120 output nodes\n",
        "ReLU\n",
        "All coupling layers 84 output nodes\n",
        "ReLU\n",
        "All coupling layers Number of output nodes 10\n",
        "softmax function\n",
        "[Problem 9] (Advance assignment) Survey of famous image recognition models\n",
        "Typical CNN structures include AlexNet (2012) and VGG16 (2014). Many of these are already available in frameworks.\n",
        "\n",
        "Please do a brief research on what they are and summarize them. It is a good idea to at least look at the names.\n",
        "\n",
        "《Reference》\n",
        "\n",
        "Applications-Keras Documentation\n",
        "\n",
        "[Problem 10] Calculation of output size and number of parameters\n",
        "When building a CNN model, it is necessary to pre-compute the number of features at the stage of input to the full join layer.\n",
        "\n",
        "Also, when dealing with huge models, the number of parameters becomes essential due to memory and calculation speed. The framework can show you the number of parameters in each layer, but you need to understand the meaning of the parameters to be able to adjust them appropriately.\n",
        "\n",
        "Calculate the output size and the number of parameters for the following three convolution layers. For the number of parameters, please also consider the bias term.\n",
        "\n",
        "1.\n",
        "\n",
        "Input size : 144 x 144, 3 channels\n",
        "Filter size: 3 x 3, 6 channels\n",
        "Stride : 1\n",
        "Padding: none\n",
        "2.\n",
        "\n",
        "Input size : 60x60, 24 channels\n",
        "Filter size: 3 x 3, 48 channels\n",
        "Stride : 1\n",
        "Padding: none\n",
        "3.\n",
        "\n",
        "Input size : 20x20, 10 channels\n",
        "Filter size: 3 x 3, 20 channels\n",
        "Stride: 2\n",
        "Padding: none\n",
        "The last example is a case where you can't get the convolution just right. The framework sometimes does not look at the extra pixels, so consider that when calculating. This is an example of why such a setting is not desirable, as it will result in missing edges.\n",
        "\n",
        "[Problem 11] (Advance assignment) Survey on filter size\n",
        "Convolutional layers have a hyperparameter called filter size, which is mostly used nowadays in 2D convolutional layers: 3×3 and 1×1. Please look up each of the following and explain them in your own way.\n",
        "\n",
        "Why 3×3 filters are commonly used instead of larger ones such as 7×7\n",
        "The effect of a 1 x 1 filter with no height or width direction"
      ],
      "metadata": {
        "id": "A8X8CKdxVnEC"
      }
    }
  ]
}