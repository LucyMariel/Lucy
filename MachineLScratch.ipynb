{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfpugXYJvj8/Qtv43+mNqy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucyMariel/Lucy/blob/master/MachineLScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understand the role of training and test data.\n",
        "\n",
        "Scratch definition: The idea here is to use basic libraries like NumPy to implement well-known classes and algorithms of machine learning.\n",
        "First, start with the train_test_split class. This is used to split the dataset into a training (learning the model) set and a test (testing the model) set.\n",
        "Let's implement train_test_split from scikit-learn from scratch."
      ],
      "metadata": {
        "id": "mhrGkwH7pksv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lxKJ3NUKpJQ4"
      },
      "outputs": [],
      "source": [
        "def scratch_train_test_split(X,y,train_size=0.8,random_state=0):\n",
        "    np.random.seed(random_state)\n",
        "    y = y.reshape(-1,1)\n",
        "    Xy = np.concatenate([X,y],axis=1)\n",
        "    size = len(Xy)\n",
        "    pick = int(np.round(size*train_size))\n",
        "    train_pick = np.random.choice(np.arange(size),pick,replace=False)\n",
        "    test_pick = np.delete(np.arange(size),train_pick)\n",
        "    train = Xy[train_pick,:]\n",
        "    test = Xy[test_pick,:]\n",
        "    X_train = train[:,0:(Xy.shape[1]-y.shape[1])].reshape(-1,X.shape[1])\n",
        "    y_train = train[:,-y.shape[1]].reshape(-1,)\n",
        "    X_test = test[:,0:(Xy.shape[1]-y.shape[1])].reshape(-1,X.shape[1])\n",
        "    y_test = test[:,-y.shape[1]].reshape(-1,)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 1: Function definition. Receives explanatory variable X, objective variable y, training data ratio train_size, and random fixed value random_state as arguments.\n",
        "\n",
        "Line 2: Fixed random numbers\n",
        "\n",
        "Line 3: transform the shape of y\n",
        "\n",
        "Line 4: Join X,y\n",
        "\n",
        "Line 5: Get data length\n",
        "\n",
        "Line 6: Get random index of training data\n",
        "\n",
        "Line 7: Get test data index randomly\n",
        "\n",
        "Lines 8-9: split into training data and test data\n",
        "\n",
        "Lines 10 to 13: Split the training data and test data into objective and explanatory variables, respectively\n",
        "\n",
        "Line 14: return as a return value"
      ],
      "metadata": {
        "id": "cO58IlmtqX3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Iris data set\n",
        "\n",
        "Line 1: Import Numpy\n",
        "\n",
        "Line 2: Introduction of iris data\n",
        "\n",
        "Line 3: Assign iris data to variable data\n",
        "\n",
        "Line 4: Assign feature value to variable X\n",
        "\n",
        "Line 5: Assign target variable to variable y\n",
        "\n",
        "Line 6: Execute the scratch_train_test_split function implemented by scratch\n",
        "\n",
        "Lines 7 to 12: Check the number of rows and columns before and after splitting"
      ],
      "metadata": {
        "id": "3IuQJO6lqv3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
        "print(f'X', X.shape)\n",
        "print(f'y', y.shape)\n",
        "print(f'X_train', X_train.shape)\n",
        "print(f'X_test', X_test.shape)\n",
        "print(f'y_train', y_train.shape)\n",
        "print(f'y_test', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdKKajE1qu6G",
        "outputId": "af12ba6a-da7a-45a5-ebcc-7f64aec60ee0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X (150, 4)\n",
            "y (150,)\n",
            "X_train (120, 4)\n",
            "X_test (30, 4)\n",
            "y_train (120,)\n",
            "y_test (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the expected output results are obtained, it can be said that the scratch implementation is working correctly.\n",
        "In addition, in this case, it can be confirmed that the same output results are obtained when the same data is input to train_test_split of scikit-learn."
      ],
      "metadata": {
        "id": "CxbWdljarDMW"
      }
    }
  ]
}